{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b4f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d06d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import MultiheadAttention\n",
    "import numpy as np\n",
    "\n",
    "# Sanity constants\n",
    "name = \"attn_cmp\"\n",
    "batch = 2\n",
    "seq_len = 2048\n",
    "n_dims = 768\n",
    "n_heads = 12\n",
    "n_layers = 6\n",
    "ff_mult = 4\n",
    "head_dim = n_dims // n_heads\n",
    "dtype = torch.float16\n",
    "device = \"cuda\"\n",
    "seed = 42\n",
    "\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36563bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy input\n",
    "x = torch.randn(seq_len, batch, n_dims, dtype=dtype, device=device)  # shape: [T, B, D]\n",
    "\n",
    "# Extract components\n",
    "head_dim = n_dims // n_heads\n",
    "\n",
    "# 1. Setup PyTorch Attention\n",
    "attn = torch.nn.MultiheadAttention(\n",
    "  embed_dim=n_dims, \n",
    "  num_heads=n_heads, \n",
    "  bias=True, \n",
    "  dropout=0.0, \n",
    "  batch_first=False, \n",
    "  dtype=dtype, \n",
    "  device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3eecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lkeravnos import Transformer\n",
    "\n",
    "# Construct CUDA transformer\n",
    "Transformer.construct(\n",
    "  name, \n",
    "  batch_size=batch, \n",
    "  sequence_length=seq_len, \n",
    "  num_dims=n_dims, \n",
    "  num_heads=n_heads, \n",
    "  num_layers=n_layers, \n",
    "  ff_multiplier=ff_mult, \n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d0d0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformer.get_info(\"attn_cmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb736538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_tensor_to_uint16_numpy(tensor: torch.Tensor) -> np.ndarray:\n",
    "    \"\"\"Convert torch.float16 Tensor to np.uint16 using raw memory.\"\"\"\n",
    "    return tensor.cpu().numpy().view(np.uint16)\n",
    "\n",
    "with torch.no_grad():\n",
    "  qkv_weight = attn.in_proj_weight  # shape: [3D, D]\n",
    "  qkv_bias = attn.in_proj_bias      # shape: [3D]\n",
    "  out_weight = attn.out_proj.weight  # [D, D]\n",
    "  out_bias = attn.out_proj.bias      # [D]\n",
    "\n",
    "  # .reshape(...).contiguous() just to be safe\n",
    "  qkv_weight_np = half_tensor_to_uint16_numpy(qkv_weight.reshape(3, n_dims, n_dims).contiguous())\n",
    "  qkv_bias_np = half_tensor_to_uint16_numpy(qkv_bias.reshape(3, n_dims).contiguous())\n",
    "  out_weight_np = half_tensor_to_uint16_numpy(out_weight.contiguous())\n",
    "  out_bias_np = half_tensor_to_uint16_numpy(out_bias.contiguous())\n",
    "\n",
    "  Transformer.edit_tensor(name, \"qkv_proj\", qkv_weight_np)\n",
    "  Transformer.edit_tensor(name, \"qkv_proj_bias\", qkv_bias_np)\n",
    "  Transformer.edit_tensor(name, \"out_proj\", out_weight_np)\n",
    "  Transformer.edit_tensor(name, \"out_proj_bias\", out_bias_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbda74e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embed = x.transpose(0, 1).contiguous().view(batch * seq_len, n_dims).cpu().numpy().view(np.uint16)\n",
    "Transformer.edit_tensor(name, \"input_embed\", token_embed, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7247c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformer.causal_self_attention(name, use_bias=True, dropout=0.0, seed=42, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ec591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv_cuda = Transformer.get_tensor(name, \"qkv_matrix\", True)  # shape: [B, T, 3, D]\n",
    "qkv_cuda = torch.from_numpy(qkv_cuda.view(np.float16)).to(dtype).to(device)\n",
    "print(qkv_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a654c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv_ref = torch.nn.functional.linear(x, qkv_weight, qkv_bias)\n",
    "qkv_ref = qkv_ref.view(batch, seq_len, 3, n_dims).contiguous()  # [B, T, 3, D]\n",
    "print(qkv_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657330c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = torch.abs(qkv_ref - qkv_cuda)\n",
    "max_diff = diff.max()\n",
    "print(\"Max diff:\", max_diff.item())\n",
    "\n",
    "if max_diff < 1e-2:\n",
    "    print(\"✅ QKV projection matches!\")\n",
    "else:\n",
    "    print(\"❌ QKV projection mismatch!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9266d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn.eval()\n",
    "with torch.no_grad():\n",
    "  qkv_ref_pytorch, _ = attn(x, x, x, need_weights=True, average_attn_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7590201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the raw Q, K for inspection\n",
    "qkv = torch.nn.functional.linear(x, qkv_weight, qkv_bias)  # [T, B, 3D]\n",
    "qkv = qkv.view(seq_len, batch, 3, n_heads, head_dim).permute(2, 1, 3, 0, 4)  # [3, B, H, T, D]\n",
    "q, k, v = qkv[0], qkv[1], qkv[2]  # each: [B, H, T, D]\n",
    "\n",
    "# Compute attention scores manually (before softmax)\n",
    "q_scaled = q / head_dim**0.5\n",
    "attn_scores_ref = torch.einsum(\"bhid,bhjd->bhij\", q_scaled, k)  # [B, H, T, T]\n",
    "\n",
    "# Apply causal mask if needed\n",
    "mask = torch.triu(torch.ones(seq_len, seq_len, device=device, dtype=torch.bool), diagonal=1)\n",
    "attn_scores_ref = attn_scores_ref.masked_fill(mask, float(\"-inf\"))\n",
    "\n",
    "# Apply softmax\n",
    "attn_probs_ref = torch.softmax(attn_scores_ref, dim=-1)  # [B, H, T, T]\n",
    "\n",
    "# Apply dropout\n",
    "dropout_p = 0.0  # or 0.1 if you want to test that too\n",
    "if dropout_p > 0.0:\n",
    "    attn_probs_ref = torch.nn.functional.dropout(attn_probs_ref, p=dropout_p, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92796860",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_probs_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3352a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch CUDA side output\n",
    "attn_probs_cuda = Transformer.get_tensor(name, \"attention_scores\")\n",
    "attn_probs_cuda = torch.from_numpy(attn_probs_cuda.view(np.float16)).to(dtype).to(device)\n",
    "attn_probs_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec24519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum over keys for each query: should be ≈1\n",
    "for t in range(head_dim): print(attn_probs_cuda[0, 3, t, :].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf37526",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(attn_probs_ref, attn_probs_cuda, rtol=1e-2, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecc4191",
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.abs(attn_probs_cuda - attn_probs_ref) > 1e-2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e22b5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keravnos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
